<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Shell/python | 游响云停]]></title>
  <link href="http://rangochan.github.com/blog/categories/shell-slash-python/atom.xml" rel="self"/>
  <link href="http://rangochan.github.com/"/>
  <updated>2014-04-14T17:28:21+08:00</updated>
  <id>http://rangochan.github.com/</id>
  <author>
    <name><![CDATA[Rangochan]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Shell中实现文件锁]]></title>
    <link href="http://rangochan.github.com/blog/2014/04/13/shellzhong-shi-xian-wen-jian-suo/"/>
    <updated>2014-04-13T21:19:21+08:00</updated>
    <id>http://rangochan.github.com/blog/2014/04/13/shellzhong-shi-xian-wen-jian-suo</id>
    <content type="html"><![CDATA[<p>1.背景</p>

<p>当多个进程可能会对同样的数据执行操作时，这些进程需要保证其它进程没有在操作，以免损坏数据。通常，这样的进程会使用一个“锁文件”，也就是建立一个文件来告诉别的进程自己在运行<!--more-->，如果检测到那个文件存在则认为有操作同样数据的进程在工作。这样的问题是，进程不小心意外死亡了，没有清理掉那个锁文件，那么只能由用户手动来清理了。</p>

<p>2.关于flock</p>

<p>flock 是对于整个文件的建议性锁。也就是说，如果一个进程在一个文件（inode）上放了锁，那么其它进程是可以知道的。（建议性锁不强求进程遵守。）最棒的一点是，它的第一个参数是文件描述符，在此文件描述符关闭时，锁会自动释放。而当进程终止时，所有的文件描述符均会被关闭。</p>

<ol>
<li>shell中实现flock系统调用的命令是flock，其使用格式有以下两种（man flock）</li>
</ol>


<p>flock [-sxon] [-w timeout] lockfile [-c] command&hellip;
flock [-sxun] [-w timeout] fd</p>

<p>选项和参数：</p>

<p>-s,&mdash;shared：获取一个共享锁，在定向为某文件的FD上设置共享锁而未释放锁的时间内，其他进程试图在定向为此文件的FD上设置独占锁的请求失败，而其他进程试图在定向为此文件的FD上设置共享锁的请求会成功。</p>

<p>-x，-e，&mdash;exclusive：获取一个排它锁，或者称为写入锁，为默认项</p>

<p>-u，&mdash;unlock：手动释放锁，一般情况不必须，当FD关闭时，系统会自动解锁，此参数用于脚本命令一部分需要异步执行，一部分可以同步执行的情况。</p>

<p>-n，&mdash;nb, &mdash;nonblock：非阻塞模式，当获取锁失败时，返回1而不是等待</p>

<p>-w, &mdash;wait, &mdash;timeout seconds：设置阻塞超时，当超过设置的秒数时，退出阻塞模式，返回1，并继续执行后面的语句</p>

<p>-o, &mdash;close：表示当执行command前关闭设置锁的FD，以使command的子进程不保持锁。</p>

<p>-c, &mdash;command command：在shell中执行其后的语句</p>

<ol>
<li>shell中实现排它锁避免脚本重复执行</li>
</ol>


<p>Linux中的例行性工作排程crontab会定时执行一些脚本，但脚本的执行时间往往无法控制，当脚本执行时间过长时，可能会导致上一次任务的脚本还没执行完，下一次任务的脚本又开始执行了。这种情况下可能会出现一些并发问题，严重时会导致出现脏数据/性能瓶颈的恶性循环。</p>

<p>通过使用flock建立排它锁可以规避这个问题，如果一个进程对某个加了排他锁，则其它进程无法加锁，可以选择等待超时或马上返回。测试实例如下：</p>

<p>4.1 创建执行脚本</p>

<h1>cat /scripts/shell/file_lock.sh</h1>

<h1>!/bin/bash</h1>

<h1>Description: test for file flock</h1>

<p>PATH=/bin:/sbin:/usr/bin:/usr/sbin:/usr/local/bin:/usr/local/sbin:~/bin
export PATH</p>

<p>echo &ldquo;&rdquo;
echo &ldquo;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&rdquo;</p>

<p>echo &ldquo;start at <code>date '+%Y-%m-%d %H:%M:%S'</code> &hellip;&rdquo;</p>

<p>sleep 140s</p>

<p>echo &ldquo;finished at <code>date '+%Y-%m-%d %H:%M:%S'</code> &hellip;&rdquo;</p>

<p>4.2 创建定时任务：测试排它锁</p>

<h1>crontab -e</h1>

<ul>
<li><ul>
<li><ul>
<li><ul>
<li><ul>
<li>flock -xn /dev/shm/test.lock -c &ldquo;sh /scripts/shell/file_lock.sh > /root/stdout.log&rdquo;</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>


<p>每分钟执行一次该脚本，并将输出信息写入到stdout.log</p>

<p>查看输出日志如下：</p>

<hr />

<p>start at 2014-04-10 10:23:01 &hellip;            #获取锁</p>

<p>finish at 2014-04-10 10:25:21 &hellip;           #释放锁</p>

<hr />

<p>start at 2014-04-10 10:26:01 &hellip;            #10:27:00及10:28:00启动的定时任务由于无法获取锁，以失败而退出执行，直到10:26:00才获取到锁</p>

<p>finish at 2014-04-10 10:28:21 &hellip;</p>

<p>4.3 测试排它锁，加上等待超时</p>

<ul>
<li><ul>
<li><ul>
<li><ul>
<li><ul>
<li>flock -x -w 20 /dev/shm/test.lock -c &ldquo;sh /scripts/shell/file_lock.sh > /root/stdout.log&rdquo;</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>


<p>查看日志输出信息：</p>

<hr />

<p>start at 2014-04-10 10:29:01 &hellip;</p>

<p>finish at 2014-04-10 10:31:21 &hellip;</p>

<hr />

<p>start at 2014-04-10 10:31:21 &hellip;    #10:31:00启动的定时任务等待了20秒后，上一个任务释放了锁，所以此任务可以马上拿到锁，并继续执行</p>

<p>finish at 2014-04-10 10:33:41 &hellip;</p>
]]></content>
  </entry>
  
</feed>
